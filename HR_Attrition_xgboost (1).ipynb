{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install fosforml numpy pandas matplotlib scikit-learn seaborn python-dateutil\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install fosforml \n",
    "!pip install fosforio\n",
    "!pip install -U cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc44edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy xgboost pandas dice-ml tabulate numpy scikit-learn pandas-profiling plotly matplotlib scipy statsmodels seaborn pydantic-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b12a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574798e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "my_session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970ff62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'ATTRITION_TABLE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96e748d-8abc-410c-bf48-be2206e0707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = my_session.sql(\"select * from {}\".format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134ef637-cba9-4cf7-a388-9f6ff4127fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927662fa-ee34-4e48-b27a-2250be087ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE_ID                                        0\n",
      "TENURE_MONTHS                                      0\n",
      "BIRTH_YEAR                                         0\n",
      "AGE                                                0\n",
      "SENIORITY                                          0\n",
      "SCHOOL_ENDDATE                                     0\n",
      "MONTHS_AFTER_COLLEGE                               0\n",
      "PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH        0\n",
      "PEOPLE_JOINED_AND_NEVER_LEFT                       0\n",
      "POPULATION                                         0\n",
      "CHURN_OTHER                                        0\n",
      "CHURN_F                                            0\n",
      "SUM_OF_TENURE                                      0\n",
      "SUM_OF_AGE                                         0\n",
      "JOB_STARTDATE                                      0\n",
      "JOB_ENDDATE                                    90076\n",
      "SALARY                                             0\n",
      "JOB_SATISFACTION                                   0\n",
      "PERCENTAGE_SALARY_HIKE                             0\n",
      "PERFORMANCE_RATING                                 0\n",
      "OVER_TIME                                          0\n",
      "RELATIONSHIP_SATISFACTION                          0\n",
      "CHURN_VALUE                                        0\n",
      "CHURN                                              0\n",
      "CITY                                               0\n",
      "DISTANCE                                           0\n",
      "DEGREE_CLEAN                                       0\n",
      "ETHNICITY                                          0\n",
      "MARITAL_STATUS                                     0\n",
      "MAPPED_ROLE                                        0\n",
      "COMPANY_NAME                                       0\n",
      "ORGANIZATION_TYPE                                  0\n",
      "ORGANIZATION_OWNERSHIP                             0\n",
      "STATE                                              0\n",
      "COUNTRY                                            0\n",
      "GENDER                                             0\n",
      "OVERTIME_HOURS                                     0\n",
      "WORK_LIFE_BALANCE                                  0\n",
      "BUSINESS_TRAVEL                                    0\n",
      "ENVIRONMENT_SATISFACTION                           0\n",
      "USER_ID                                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c3b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df = pandas_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568f155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE_ID                                    0\n",
      "TENURE_MONTHS                                  0\n",
      "BIRTH_YEAR                                     0\n",
      "AGE                                            0\n",
      "SENIORITY                                      0\n",
      "SCHOOL_ENDDATE                                 0\n",
      "MONTHS_AFTER_COLLEGE                           0\n",
      "PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH    0\n",
      "PEOPLE_JOINED_AND_NEVER_LEFT                   0\n",
      "POPULATION                                     0\n",
      "CHURN_OTHER                                    0\n",
      "CHURN_F                                        0\n",
      "SUM_OF_TENURE                                  0\n",
      "SUM_OF_AGE                                     0\n",
      "JOB_STARTDATE                                  0\n",
      "JOB_ENDDATE                                    0\n",
      "SALARY                                         0\n",
      "JOB_SATISFACTION                               0\n",
      "PERCENTAGE_SALARY_HIKE                         0\n",
      "PERFORMANCE_RATING                             0\n",
      "OVER_TIME                                      0\n",
      "RELATIONSHIP_SATISFACTION                      0\n",
      "CHURN_VALUE                                    0\n",
      "CHURN                                          0\n",
      "CITY                                           0\n",
      "DISTANCE                                       0\n",
      "DEGREE_CLEAN                                   0\n",
      "ETHNICITY                                      0\n",
      "MARITAL_STATUS                                 0\n",
      "MAPPED_ROLE                                    0\n",
      "COMPANY_NAME                                   0\n",
      "ORGANIZATION_TYPE                              0\n",
      "ORGANIZATION_OWNERSHIP                         0\n",
      "STATE                                          0\n",
      "COUNTRY                                        0\n",
      "GENDER                                         0\n",
      "OVERTIME_HOURS                                 0\n",
      "WORK_LIFE_BALANCE                              0\n",
      "BUSINESS_TRAVEL                                0\n",
      "ENVIRONMENT_SATISFACTION                       0\n",
      "USER_ID                                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Original_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd5d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Original_df.drop([\"USER_ID\", \"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\", \"SCHOOL_ENDDATE\",\"CHURN_VALUE\",\"PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH\",\"PEOPLE_JOINED_AND_NEVER_LEFT\",\"POPULATION\",\"CHURN_OTHER\",\"CHURN_F\",\"SUM_OF_TENURE\",\"SUM_OF_AGE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2f28381",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"MAPPED_ROLE\",\"GENDER\", \"ETHNICITY\",\"ORGANIZATION_TYPE\", \"ORGANIZATION_OWNERSHIP\",\"COMPANY_NAME\",\"CITY\",\"STATE\",\"DISTANCE\",\"COUNTRY\",\"DEGREE_CLEAN\",\n",
    "                       \"NEW_DEVICE_INDICATOR\",\"BUSINESS_TRAVEL\",\"ENVIRONMENT_SATISFACTION\",\"JOB_SATISFACTION\",\"MARITAL_STATUS\",\"OVER_TIME\",\"PERFORMANCE_RATING\",\"RELATIONSHIP_SATISFACTION\",\"WORK_LIFE_BALANCE\"]\n",
    "NUMERICAL_COLUMNS = [\"SALARY\", \"SENIORITY\", \"TENURE_MONTHS\", \"MONTHS_AFTER_COLLEGE\", \"BIRTH_YEAR\",\"AGE\",\"OVERTIME_HOURS\",\"PERCENTAGE_SALARY_HIKE\"]\n",
    "LABEL_COLUMNS = [\"CHURN\"]\n",
    "DROPPED_COLUMNS = [\"USER_ID\", \"EMPLOYEE_ID\", \"JOB_STARTDATE\", \"JOB_ENDDATE\", \"SCHOOL_ENDDATE\",\"CHURN_VALUE\",\"PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH\",\"PEOPLE_JOINED_AND_NEVER_LEFT\",\"POPULATION\",\"CHURN_OTHER\",\"CHURN_F\",\"SUM_OF_TENURE\",\"SUM_OF_AGE\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7722e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter feature columns\n",
    "feature_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS\n",
    "feature_columns = [col for col in feature_columns if col in Original_df.columns]\n",
    "LABEL_COLUMNS = [col for col in LABEL_COLUMNS if col in Original_df.columns]\n",
    " \n",
    "# Split data into features and labels\n",
    "X = Original_df[feature_columns + DROPPED_COLUMNS]\n",
    "y = Original_df[LABEL_COLUMNS].values.ravel()  # Flatten to 1D array for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7786299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37c79dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e463892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41985 entries, 265369 to 296762\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   MAPPED_ROLE                                  41985 non-null  object \n",
      " 1   GENDER                                       41985 non-null  object \n",
      " 2   ETHNICITY                                    41985 non-null  object \n",
      " 3   ORGANIZATION_TYPE                            41985 non-null  object \n",
      " 4   ORGANIZATION_OWNERSHIP                       41985 non-null  object \n",
      " 5   COMPANY_NAME                                 41985 non-null  object \n",
      " 6   CITY                                         41985 non-null  object \n",
      " 7   STATE                                        41985 non-null  object \n",
      " 8   DISTANCE                                     41985 non-null  object \n",
      " 9   COUNTRY                                      41985 non-null  object \n",
      " 10  DEGREE_CLEAN                                 41985 non-null  object \n",
      " 11  BUSINESS_TRAVEL                              41985 non-null  object \n",
      " 12  ENVIRONMENT_SATISFACTION                     41985 non-null  object \n",
      " 13  JOB_SATISFACTION                             41985 non-null  object \n",
      " 14  MARITAL_STATUS                               41985 non-null  object \n",
      " 15  OVER_TIME                                    41985 non-null  object \n",
      " 16  PERFORMANCE_RATING                           41985 non-null  object \n",
      " 17  RELATIONSHIP_SATISFACTION                    41985 non-null  object \n",
      " 18  WORK_LIFE_BALANCE                            41985 non-null  object \n",
      " 19  SALARY                                       41985 non-null  float64\n",
      " 20  SENIORITY                                    41985 non-null  int8   \n",
      " 21  TENURE_MONTHS                                41985 non-null  int16  \n",
      " 22  MONTHS_AFTER_COLLEGE                         41985 non-null  int16  \n",
      " 23  BIRTH_YEAR                                   41985 non-null  object \n",
      " 24  AGE                                          41985 non-null  object \n",
      " 25  OVERTIME_HOURS                               41985 non-null  int8   \n",
      " 26  PERCENTAGE_SALARY_HIKE                       41985 non-null  int8   \n",
      " 27  USER_ID                                      41985 non-null  int32  \n",
      " 28  EMPLOYEE_ID                                  41985 non-null  object \n",
      " 29  JOB_STARTDATE                                41985 non-null  object \n",
      " 30  JOB_ENDDATE                                  41985 non-null  object \n",
      " 31  SCHOOL_ENDDATE                               41985 non-null  object \n",
      " 32  CHURN_VALUE                                  41985 non-null  object \n",
      " 33  PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH  41985 non-null  int16  \n",
      " 34  PEOPLE_JOINED_AND_NEVER_LEFT                 41985 non-null  int16  \n",
      " 35  POPULATION                                   41985 non-null  int16  \n",
      " 36  CHURN_OTHER                                  41985 non-null  int16  \n",
      " 37  CHURN_F                                      41985 non-null  int16  \n",
      " 38  SUM_OF_TENURE                                41985 non-null  int32  \n",
      " 39  SUM_OF_AGE                                   41985 non-null  int32  \n",
      "dtypes: float64(1), int16(7), int32(3), int8(3), object(26)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93eb2566",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NEW_DEVICE_INDICATOR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/__init__.py:447\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 447\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NEW_DEVICE_INDICATOR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create pipeline\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     29\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     30\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier())\n\u001b[1;32m     31\u001b[0m ])\n\u001b[0;32m---> 33\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m result \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:423\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 423\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    375\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:751\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    754\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:459\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    457\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    458\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 459\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/__init__.py:455\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    452\u001b[0m             column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 455\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    " \n",
    "# Define transformers\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    ")\n",
    " \n",
    "numerical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler(clip=True)\n",
    ")\n",
    " \n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, CATEGORICAL_COLUMNS),\n",
    "        ('num', numerical_transformer, NUMERICAL_COLUMNS)\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da258f46-6664-4e61-bb10-c0a638726771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MAPPED_ROLE', 'GENDER', 'ETHNICITY', 'ORGANIZATION_TYPE',\n",
      "       'ORGANIZATION_OWNERSHIP', 'COMPANY_NAME', 'CITY', 'STATE', 'DISTANCE',\n",
      "       'COUNTRY', 'DEGREE_CLEAN', 'BUSINESS_TRAVEL',\n",
      "       'ENVIRONMENT_SATISFACTION', 'JOB_SATISFACTION', 'MARITAL_STATUS',\n",
      "       'OVER_TIME', 'PERFORMANCE_RATING', 'RELATIONSHIP_SATISFACTION',\n",
      "       'WORK_LIFE_BALANCE', 'SALARY', 'SENIORITY', 'TENURE_MONTHS',\n",
      "       'MONTHS_AFTER_COLLEGE', 'BIRTH_YEAR', 'AGE', 'OVERTIME_HOURS',\n",
      "       'PERCENTAGE_SALARY_HIKE', 'USER_ID', 'EMPLOYEE_ID', 'JOB_STARTDATE',\n",
      "       'JOB_ENDDATE', 'SCHOOL_ENDDATE', 'CHURN_VALUE',\n",
      "       'PEOPLE_JOINED_BEFORE_AND_LEFT_IN_THIS_MONTH',\n",
      "       'PEOPLE_JOINED_AND_NEVER_LEFT', 'POPULATION', 'CHURN_OTHER', 'CHURN_F',\n",
      "       'SUM_OF_TENURE', 'SUM_OF_AGE'],\n",
      "      dtype='object')\n",
      "['MAPPED_ROLE', 'GENDER', 'ETHNICITY', 'ORGANIZATION_TYPE', 'ORGANIZATION_OWNERSHIP', 'COMPANY_NAME', 'CITY', 'STATE', 'DISTANCE', 'COUNTRY', 'DEGREE_CLEAN', 'NEW_DEVICE_INDICATOR', 'BUSINESS_TRAVEL', 'ENVIRONMENT_SATISFACTION', 'JOB_SATISFACTION', 'MARITAL_STATUS', 'OVER_TIME', 'PERFORMANCE_RATING', 'RELATIONSHIP_SATISFACTION', 'WORK_LIFE_BALANCE']\n",
      "['SALARY', 'SENIORITY', 'TENURE_MONTHS', 'MONTHS_AFTER_COLLEGE', 'BIRTH_YEAR', 'AGE', 'OVERTIME_HOURS', 'PERCENTAGE_SALARY_HIKE']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(CATEGORICAL_COLUMNS)\n",
    "print(NUMERICAL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f24f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "filename = \"HR_Attrition.joblib\"\n",
    "dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c20f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "\n",
    "from refractml.constants import MLModelFlavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data_json = eval(payload)\n",
    "    data = pd.DataFrame([data_json])\n",
    "    prediction = str(model.predict(data)[0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd \n",
    "payload = str(X_test.iloc[123].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "\n",
    "print(score(pipeline, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5169f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model.\n",
    "tmp = register_model(pipeline, \n",
    "               score, \n",
    "               name=\"HR_ATTRITION_ML_MODEL\", \n",
    "               description=\"Analyzing_HR_Attrition_trained_using _ml\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred, \n",
    "               features=X_train.columns,\n",
    "               labels=[0,1],\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               prob=y_prob,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               target_names=['NOT LEFT','LEFT'],\n",
    "               kyd=True, kyd_score = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = {\"payload\": X_test.iloc[0].to_dict()}\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ef3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.predict(X_test)\n",
    "result_prob = pipeline.predict_proba(X_test)\n",
    "pred_df = X_test.copy()\n",
    "result = result\n",
    "result_prob = result_prob\n",
    "pred_df[\"PREDICTION\"] = result\n",
    "pred_df[\"PROB\"] = result_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1df31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, log_loss, roc_auc_score\n",
    " \n",
    "# Check lengths\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "print(\"Length of y_pred:\", len(y_pred))\n",
    " \n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = sum(y_test == y_pred) / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    " \n",
    "# Calculate additional metrics\n",
    "log_loss_value = log_loss(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob[:, 1])  # Assuming class 1 is the positive class\n",
    " \n",
    "print(\"Log Loss:\", log_loss_value)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c775c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, pred_df[\"PROB\"])\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred_df[\"PROB\"])\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Radnomforest')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f661cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, pred_df[\"PROB\"])\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Randomforest')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Not Churn','Churn'],\n",
    "            yticklabels=['Not CHurn','Churn'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = pd.DataFrame({\"ns_probs\":ns_probs,\n",
    "                            \"y_test\":y_test,\n",
    "                            \"y_pred\":pred_df[\"PREDICTION\"],\n",
    "                            \"act_probs\":pred_df[\"PROB\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data.to_csv(\"/data/scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5599fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define or use the prediction function\n",
    "def model_prediction_score_func(dataframe):\n",
    "    # Ensure 'dataframe' has the correct features required by the model\n",
    "    return pipeline.predict(dataframe)  # Use your trained pipeline/model here\n",
    " \n",
    "# Assuming df is your input DataFrame with the necessary features\n",
    "Original_df['Model_Output'] = model_prediction_score_func(Original_df)\n",
    " \n",
    "# If you have a DataFrame with test data and you want to merge predictions\n",
    "# Assuming X_test is the DataFrame for which predictions are made\n",
    "#X_test_with_predictions = X_test.copy()\n",
    "#X_test_with_predictions['Model_Output'] = model_prediction_score_func(X_test)\n",
    " \n",
    "# Display the first few rows to verify\n",
    "#print(X_test_with_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_df.to_csv(\"/data/Hr_Attrition_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = snowflake.get_connection(\"HR_ATTRITION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if 'Model_Output' in Original_df:\n",
    "    Original_df['Model_Output_Values'] = Original_df['Model_Output'].astype(bool)\n",
    "print(Original_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'HR_Attrition_Data.csv'\n",
    "Original_df.to_csv(file , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6656cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake.execute_query(f\"PUT file://{file} @HR_ANALYTIC.PUBLIC.HR_ATTRITION_STAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
